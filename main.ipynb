{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/somwrks/AI-Solar-Panel/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUFXapyFjPJi"
      },
      "source": [
        "# Self Rotatory Solar Panel\n",
        "\n",
        "This Project utilizes various vision models to train on planet sun labelled datasets and perform validation checks to determine which model performs the best and converts the best model to tinyML Model to make it usable by microcontroller"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_xvdAxVjnnZ"
      },
      "source": [
        "## Installing Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install --upgrade pip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QyLqMe3CY_7v",
        "outputId": "4344e06c-5a84-4267-ed0f-14851329aea3"
      },
      "outputs": [],
      "source": [
        "%pip install inference tensorflow[and-cuda] tensorflow-datasets roboflow ultralytics torch torchvision matplotlib tqdm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oTtl35YjMFb"
      },
      "source": [
        "## Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89gL1DtFcJwD"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import torch\n",
        "import torchvision  \n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import shutil\n",
        "from tensorflow.keras import mixed_precision\n",
        "from roboflow import Roboflow\n",
        "import yaml\n",
        "import os\n",
        "from PIL import Image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0' \n",
        "os.environ['NO_ALBUMENTATIONS_UPDATE '] = '1'  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"GPU Available:\", tf.config.list_physical_devices())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxfmKGVicHbA",
        "outputId": "19a499a1-6748-4359-a9d5-70a2c8008741"
      },
      "outputs": [],
      "source": [
        "# List available GPUs\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "print(\"Num GPUs Available: \", len(physical_devices))\n",
        "\n",
        "if len(physical_devices) > 0:\n",
        "# Enable memory growth for all GPUs\n",
        "  for gpu in physical_devices:\n",
        "      tf.config.experimental.set_memory_growth(gpu, True)\n",
        "\n",
        "  # Use all available GPUs\n",
        "  tf.config.set_visible_devices(physical_devices, 'GPU')\n",
        "\n",
        "  # Enable XLA (Accelerated Linear Algebra) optimization\n",
        "  tf.config.optimizer.set_jit(True)\n",
        "\n",
        "  tf.config.set_visible_devices(physical_devices[0], 'GPU')\n",
        "\n",
        "  # Enable mixed precision training\n",
        "\n",
        "  policy = mixed_precision.Policy('mixed_float16')\n",
        "  mixed_precision.set_global_policy(policy)\n",
        "\n",
        "  print(\"GPU optimization settings applied successfully\")\n",
        "else:\n",
        "    print(\"No GPU available. Running on CPU.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaSvXrvGiYhx"
      },
      "source": [
        "## Loading Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import yaml\n",
        "from roboflow import Roboflow\n",
        "from PIL import Image\n",
        "\n",
        "# Download both datasets\n",
        "rf = Roboflow(api_key=\"\")\n",
        "\n",
        "# Dataset 1\n",
        "\n",
        "project1 = rf.workspace(\"yassine-pzpt7\").project(\"sun-tracking-photovoltaic-panel\")\n",
        "version1 = project1.version(2)\n",
        "dataset1 = version1.download(\"yolov8\")\n",
        "\n",
        "# Dataset 2\n",
        "project2 = rf.workspace(\"1009727588-qq-com\").project(\"sun-nxvfz\")\n",
        "dataset2 = project2.version(2).download(\"yolov8\")\n",
        "\n",
        "# Dataset 3\n",
        "project3 = rf.workspace(\"rik-tjduw\").project(\"sun-tracking-555mn\")\n",
        "version3 = project3.version(4)\n",
        "dataset3 = version3.download(\"yolov8\")\n",
        "\n",
        "# Dataset 4\n",
        "project4 = rf.workspace(\"stardetect\").project(\"solar-re1fe\")\n",
        "version4 = project4.version(1)\n",
        "dataset4 = version4.download(\"yolov8\")\n",
        "\n",
        "# Dataset 5\n",
        "project5 = rf.workspace(\"fruitdetection-ulcz9\").project(\"sun_detection-hl04q\")\n",
        "version5 = project5.version(1)\n",
        "dataset5 = version5.download(\"yolov8\")\n",
        "\n",
        "# Prepare dataset paths\n",
        "dataset1_path = dataset1.location\n",
        "dataset2_path = dataset2.location\n",
        "dataset3_path = dataset3.location\n",
        "dataset4_path = dataset4.location\n",
        "dataset5_path = dataset5.location\n",
        "\n",
        "def resize_images(directory, target_resolution=(640, 640)):\n",
        "    image_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff')\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(image_extensions):\n",
        "                image_path = os.path.join(root, file)\n",
        "                try:\n",
        "                    with Image.open(image_path) as img:\n",
        "                        img_resized = img.resize(target_resolution, Image.LANCZOS)\n",
        "                        img_resized.save(image_path)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error resizing image {image_path}: {e}\")\n",
        "\n",
        "# Function to count images in a directory\n",
        "def count_images(directory):\n",
        "    image_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff')\n",
        "    return len([f for f in os.listdir(directory) if f.lower().endswith(image_extensions)])\n",
        "\n",
        "# Function to combine datasets\n",
        "\n",
        "def combine_datasets(*dataset_paths, combined_path):\n",
        "    for split in ['train', 'valid', 'test']:\n",
        "        os.makedirs(os.path.join(combined_path, split, 'images'), exist_ok=True)\n",
        "        os.makedirs(os.path.join(combined_path, split, 'labels'), exist_ok=True)\n",
        "\n",
        "        for dataset_path in dataset_paths:\n",
        "            images_src = os.path.join(dataset_path, split, 'images')\n",
        "            labels_src = os.path.join(dataset_path, split, 'labels')\n",
        "\n",
        "            images_dst = os.path.join(combined_path, split, 'images')\n",
        "            labels_dst = os.path.join(combined_path, split, 'labels')\n",
        "\n",
        "            if os.path.exists(images_src):\n",
        "                for file in os.listdir(images_src):\n",
        "                    shutil.copy2(os.path.join(images_src, file), images_dst)\n",
        "            if os.path.exists(labels_src):\n",
        "                for file in os.listdir(labels_src):\n",
        "                    shutil.copy2(os.path.join(labels_src, file), labels_dst)\n",
        "\n",
        "\n",
        "# Combine datasets\n",
        "combined_path = './combined_dataset'\n",
        "combine_datasets(dataset1_path, dataset2_path, dataset3_path,dataset4_path, dataset5_path, combined_path=combined_path)\n",
        "\n",
        "# Resize images in the combined dataset\n",
        "for split in ['train', 'valid', 'test']:\n",
        "    images_dir = os.path.join(combined_path, split, 'images')\n",
        "    resize_images(images_dir)\n",
        "\n",
        "print(\"Images resized to target resolution.\")\n",
        "\n",
        "\n",
        "# Count images in each dataset\n",
        "train_count = len(os.listdir(os.path.join(combined_path, 'train', 'images')))\n",
        "valid_count = len(os.listdir(os.path.join(combined_path, 'valid', 'images')))\n",
        "test_count = len(os.listdir(os.path.join(combined_path, 'test', 'images')))\n",
        "num_classes = len(set([f.split('_')[0] for f in os.listdir(os.path.join(combined_path, 'train', 'labels'))]))\n",
        "\n",
        "print(f\"Number of images in training set: {train_count}\")\n",
        "print(f\"Number of images in validation set: {valid_count}\")\n",
        "print(f\"Number of images in test set: {test_count}\")\n",
        "print(f\"Total number of images: {train_count + valid_count + test_count}\")\n",
        "\n",
        "# Create YAML file for YOLOv5\n",
        "yaml_content = {\n",
        "    'train': os.path.join(combined_path, 'train'),\n",
        "    'val': os.path.join(combined_path, 'valid'),\n",
        "    'test': os.path.join(combined_path, 'test'),\n",
        "    'nc': len(os.listdir(os.path.join(combined_path, 'train', 'labels'))),\n",
        "    'names': [f'class_{i}' for i in range(len(os.listdir(os.path.join(combined_path, 'train', 'labels'))))],\n",
        "    'image_counts': {\n",
        "        'train': train_count,\n",
        "        'val': valid_count,\n",
        "        'test': test_count\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "yaml_content = {\n",
        "    'train': os.path.join(combined_path, 'train'),\n",
        "    'val': os.path.join(combined_path, 'valid'),\n",
        "    'test': os.path.join(combined_path, 'test'),\n",
        "    'nc': num_classes,\n",
        "    'names': [f'class_{i}' for i in range(num_classes)],\n",
        "}\n",
        "\n",
        "yaml_path = os.path.join(combined_path, 'dataset.yaml')\n",
        "with open(yaml_path, 'w') as yaml_file:\n",
        "    yaml.dump(yaml_content, yaml_file, default_flow_style=False)\n",
        "\n",
        "print(f\"Dataset YAML file created at: {yaml_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyPrpebpiqsh"
      },
      "source": [
        "## Setting Up Models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPQwWAkniyNk"
      },
      "source": [
        "### 1. YoloV5 (LibRT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBGiPvVpi3JA",
        "outputId": "b0950f6b-8443-4b98-e821-13e212790da4"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2bqOGxNi5In",
        "outputId": "2fa3765b-f577-42ee-96fb-bf21a0466c62"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "yolo_model = YOLO('runs/detect/train6/weights/best.pt')\n",
        "\n",
        "full_yaml_path = os.path.abspath(yaml_path)\n",
        "yolo_results = yolo_model.train(\n",
        "    data=full_yaml_path,\n",
        "    epochs=1000,  \n",
        "    imgsz=640,\n",
        "    lr0=0.001,  \n",
        "    lrf=0.0001, \n",
        "    batch=-1,  \n",
        "    device=[0],\n",
        "    augment=True,\n",
        "    cos_lr=True,\n",
        "    amp=True,  \n",
        "    resume=True,\n",
        "    patience=300,\n",
        "    mixup=0.2,  \n",
        "    mosaic=1.0, \n",
        "    close_mosaic=10  \n",
        ")\n",
        "\n",
        "# Evaluate the model after training\n",
        "metrics = yolo_model.val()\n",
        "print(f\"mAP50-95: {metrics.box.map}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GMSZU_llURV"
      },
      "source": [
        "## Testing Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5Tz077XlYs4"
      },
      "outputs": [],
      "source": [
        "# Evaluate YOLOv5\n",
        "yolo_metrics = yolo_model.val()\n",
        "\n",
        "print(\"YOLOv5 mAP:\", yolo_metrics.results_dict['metrics/mAP50-95(B)'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKcNYAa-jC7I"
      },
      "source": [
        "## Saving Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nkel_M6ZXIZ"
      },
      "outputs": [],
      "source": [
        "model.save('sun_tracker_model.h5')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pretrained Model Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Static Models from roboflow web\n",
        "\n",
        "\n",
        "| Model | mAP50-95 | Precision | Recall | Images | Type |\n",
        "|-------|----------|-----------|--------|--------|------|\n",
        "| Our YOLO model | 73.5% | 89.2% | 91.7% | 633 | YOLOv8 (custom trained) |\n",
        "| solar-re1fe/1 | 96.8% | 95.2% | 94.3% | 2684 | Roboflow 3.0 Object Detection (Fast) |\n",
        "| sun-tracking-photovoltaic-panel/1 | 98.2% | 93.7% | 93.7% | 196 | Roboflow 2.0 Object Detection (Fast) |\n",
        "| sun-tracking/3 | 92.5% | 94.7% | 91.8% | 1090 | YOLOv5 Model Upload |\n",
        "| sun-tracking-555mn/4 | 97.7% | 93.0% | 89.2% | 923 | YOLOv8n Model Upload |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "1. **sun-tracking-555mn/4**\n",
        "   - Best overall performance with 97.7% mAP\n",
        "   - YOLOv8n architecture, which is lightweight and suitable for microcontrollers\n",
        "   - Recently trained (2024-03-05)\n",
        "   - Balanced dataset size (923 images)\n",
        "\n",
        "2. **solar-re1fe/1**\n",
        "   - High performance (96.8% mAP, 95.2% precision, 94.3% recall)\n",
        "   - Largest dataset (2684 images), potentially good for generalization\n",
        "   - Roboflow 3.0 Object Detection (Fast) may be suitable for microcontrollers\n",
        "\n",
        "3. **sun-tracking-photovoltaic-panel/1**\n",
        "   - Highest mAP (98.2%)\n",
        "   - Roboflow 2.0 Object Detection (Fast) may work on microcontrollers\n",
        "   - Limited dataset (196 images) might affect generalization\n",
        "\n",
        "4. **sun-tracking/3**\n",
        "   - Lowest mAP (92.5%) among the options\n",
        "   - YOLOv5 architecture, which is generally suitable for microcontrollers\n",
        "   - Decent dataset size (1090 images)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from inference import get_model\n",
        "import supervision as sv\n",
        "import cv2\n",
        "\n",
        "# define the image url to use for inference\n",
        "image_file = \"test.jpg\"\n",
        "image = cv2.imread(image_file)\n",
        "\n",
        "# load a pre-trained yolov8n model\n",
        "model = get_model(model_id=\"sun-tracking-555mn/4\", api_key=\"\")\n",
        "\n",
        "# run inference on our chosen image, image can be a url, a numpy array, a PIL image, etc.\n",
        "results = model.infer(image)[0]\n",
        "\n",
        "# load the results into the supervision Detections api\n",
        "detections = sv.Detections.from_inference(results)\n",
        "\n",
        "# create supervision annotators\n",
        "bounding_box_annotator = sv.BoxAnnotator()\n",
        "label_annotator = sv.LabelAnnotator()\n",
        "\n",
        "# annotate the image with our inference results\n",
        "annotated_image = bounding_box_annotator.annotate(\n",
        "    scene=image, detections=detections)\n",
        "annotated_image = label_annotator.annotate(\n",
        "    scene=annotated_image, detections=detections)\n",
        "\n",
        "# display the image\n",
        "sv.plot_image(annotated_image)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyMl4YBZ3z4DAHXzq2rIaZO9",
      "collapsed_sections": [
        "J6Ap_wt6itSN",
        "dFWtiZSWi6e1"
      ],
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
